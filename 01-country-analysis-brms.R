library(tidyverse)
library(brms)
library(here)
library(mice)
library(future)
h <- here::here

set.seed(101)
source(h("R/functions.R"))


# Read in data
country_raw <- read_csv(h("country-level-amr.csv")) %>%
  dplyr::select(-continent, -region, -country, -gdp_dollars, -pubs_sum, -promed_mentions, -tourism_outbound_perc#,
                # -livestock_consumption_kg, -livestock_consumption_kg_per_pcu, -livestock_pcu
  ) %>%
  drop_na(population, gdp_per_capita) %>% # remove if population or gdp data is unavailable (usually territories)
  mutate_at(vars(ab_export_perc, ab_import_perc), ~replace_na(., 0)) %>% # assume 0 for import/export NAs
  mutate_at(vars(gdp_per_capita, migrant_pop_perc, population, livestock_consumption_kg_per_capita, tourism_inbound_perc, promed_mentions_per_capita),
            ~log(.)) %>%
  mutate(pubs_sum_per_capita = log(pubs_sum_per_capita + 1e-07)) %>%
  rename_at(vars("livestock_consumption_kg_per_capita", "migrant_pop_perc", "promed_mentions_per_capita", "pubs_sum_per_capita",
                 "gdp_per_capita" , "population", "tourism_inbound_perc"), ~paste0("ln_", .))

# View correlation matrix on raw data
country_raw %>%
  dplyr::select(-iso3c) %>%
  PerformanceAnalytics::chart.Correlation(., histogram = TRUE, pch = 19)

# par(mfrow=c(1,2))
# plot(country_raw$ln_livestock_consumption_kg_per_capita, country_raw$ln_gdp_per_capita)
# plot(country_raw$ln_livestock_consumption_kg_per_capita, country_raw$ln_migrant_pop_perc)

# Which parameters have NAs
map_int(country_raw, ~sum(is.na(.)))

# Mice settings
# helpful for setting parameters: https://stats.stackexchange.com/questions/219013/how-do-the-number-of-imputations-the-maximum-iterations-affect-accuracy-in-mul/219049
# m is the number of imputations, generally speaking, the more the better. Originally (following Rubin, 1987) 5 was considered to be enough (hence the default). So from an accuracy point of view, 5 may be sufficient. However, this was based on an efficiency argument only. In order to achieve better estimates of standard errors, more imputations are needed. These days there is a rule of thumb to use whatever the average percentage rate of missingness is - so if there is 30% missing data on average in a dataset, use 30 imputations - see Bodner (2008) and White et al (2011) for further details.
# maxit is the number of iterations for each imputation. mice uses an iterative algorithm. It is important that the imputations for all variables reach convergence, otherwise they will be inaccurate. By inspecting the trace plots generated by plot() this can be visually determined. Unlike other Gibbs sampling methods, far fewer iterations are needed - generally in the region of 20-30 or less as a rule of thumb. When the trace lines reach a value and fluctuate slightly around it, convergence has been achieved.

m <- 30
maxit <- 40

# Impute + Diagnostics
# https://stefvanbuuren.name/fimd/sec-algoptions.html#sec:convergence
# https://stefvanbuuren.name/fimd/sec-diagnostics.html

## with specified predictors
country_mice <- mice(country_raw, m=m, maxit=maxit, method='cart', seed=500)#, blocks = c("health_expend_perc", "human_consumption_ddd", "ln_livestock_consumption_kg_per_pcu", "ln_livestock_pcu"), predictorMatrix = pred_matrix) 
plot(country_mice) # On convergence, the different streams should be freely intermingled with one another, without showing any definite trends. Convergence is diagnosed when the variance between different sequences is no larger than the variance within each individual sequence.
show_imputes(country_mice, m = m, raw = country_raw)
write_rds(country_mice, h("model/mice-imputation.rds"))

imp <- complete(country_mice)

imp %>%
  dplyr::select(-iso3c) %>%
  PerformanceAnalytics::chart.Correlation(., histogram = TRUE, pch = 19)

imp %>%
  dplyr::select(-iso3c) %>%
  mutate_all(~rank(.)) %>%
  PerformanceAnalytics::chart.Correlation(., histogram = TRUE, pch = 19)

# Model Runs
# Useful checks: https://cran.r-project.org/web/packages/bayesplot/vignettes/graphical-ppcs.html

# Note about warning message

# Warning message:
#   Using only the first imputed data set. Please interpret the results with caution until a more principled approach has been implemented. 
# Note:
# brm_multiple combines the models into a single fitted model (see combine argument) 
# so it's okay to make predictions from the model object, and I think specifying newdata would mean the warning does not apply


## Full model, combine = FALSE
plan(multiprocess, workers = floor(parallel::detectCores()/4))
fit_all <- brm_multiple(bf(n_amr_events ~  ln_livestock_consumption_kg_per_capita + 
                             ln_migrant_pop_perc + ln_tourism_inbound_perc + #ln_tourism_outbound_perc +
                             ab_export_perc + health_expend_perc + 
                             human_consumption_ddd + english_spoken + 
                             ln_pubs_sum_per_capita + ln_promed_mentions_per_capita + ln_gdp_per_capita + offset(ln_population),
                           zi ~ ln_pubs_sum_per_capita + ln_promed_mentions_per_capita  + ln_gdp_per_capita + ln_population + english_spoken),
                        data = country_mice,
                        family = zero_inflated_poisson(),
                        chains = 4,
                        inits = "0", 
                        iter = 2000,
                        control = list(adapt_delta = 0.9),
                        cores = 4,
                        combine = FALSE)

write_rds(fit_all, h("model/fit_all.rds"))
fit_all_me <- furrr::future_map(fit_all, ~marginal_effects(.))
write_rds(fit_all_me, h("model/fit_all_marginal_effects.rds"))


fit_combined <- combine_models(mlist = fit_all, check_data = FALSE)
plan(multiprocess, workers = floor(parallel::detectCores()))
write_rds(fit_combined, h("model/fit_combined.rds"))
fit_combined_me <- marginal_effects(fit_combined)
write_rds(fit_combined_me, h("model/fit_combined_marginal_effects.rds"))
