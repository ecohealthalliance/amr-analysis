library(tidyverse)
library(brms)
library(here)
library(mice)
library(future)
h <- here::here

set.seed(101)
source(h("R/functions.R"))

# Read in data
country_raw <- read_csv(h("country_level_amr.csv")) %>%
  dplyr::select(-continent, -region, -country, -english_spoken) %>%
  drop_na(population, gdp_dollars) %>% # remove if population or gdp data is unavailable (usually territories)
  mutate_at(vars(pubs_sum, ab_export_perc, ab_import_perc), ~replace_na(., 0)) %>% # assume 0 for pubs_sum and ab_export NAs
  mutate_at(vars(gdp_dollars, migrant_pop_perc, population, livestock_consumption_kg_per_pcu, livestock_pcu),
            ~log(.)) %>%
  mutate(pubs_sum = log(pubs_sum + 0.1)) %>%
  rename_at(vars("livestock_consumption_kg_per_pcu", "livestock_pcu", "migrant_pop_perc", 
                   "gdp_dollars", "pubs_sum" , "population"), ~paste0("ln_", .))

# View correlation matrix
# country_raw %>%
#   dplyr::select(-iso3c) %>%
#   PerformanceAnalytics::chart.Correlation(., histogram = TRUE, pch = 19)

# Which parameters have NAs
map_int(country_raw, ~sum(is.na(.)))

# Specify predictors for imputation
# Note that it might be best to include all variables: 
# https://stefvanbuuren.name/fimd/sec-modelform.html#sec:predictors
# Conditioning on all other data is often reasonable for small to medium datasets, containing up to, say, 20â€“30 variables, without derived variables, interactions effects and other complexities. As a general rule, using every bit of available information yields multiple imputations that have minimal bias and maximal efficiency (Meng 1994; Collins, Schafer, and Kam 2001). It is often beneficial to choose as large a number of predictors as possible. Including as many predictors as possible tends to make the MAR assumption more plausible, thus reducing the need to make special adjustments for MNAR mechanisms (Schafer 1997).
pred_matrix <- matrix(nrow = 4, ncol = ncol(country_raw), 
                      dimnames = list(c("health_expend_perc", "human_consumption_ddd", "ln_livestock_consumption_kg_per_pcu", "ln_livestock_pcu"),
                                      colnames(country_raw)), data = 0)
pred_matrix["health_expend_perc", c("ln_gdp_dollars", "ln_population")] <- 1
pred_matrix["human_consumption_ddd", c("ln_gdp_dollars", "ln_population", "ab_export_perc", "ab_import_perc")] <- 1
pred_matrix["ln_livestock_consumption_kg_per_pcu", c("ln_gdp_dollars", "ln_population", "ab_export_perc", "ab_import_perc", "ln_livestock_pcu", "human_consumption_ddd")] <- 1
pred_matrix["ln_livestock_pcu", c("ln_gdp_dollars", "ln_population")] <- 1

# Mice settings
# helpful for setting parameters: https://stats.stackexchange.com/questions/219013/how-do-the-number-of-imputations-the-maximum-iterations-affect-accuracy-in-mul/219049
# m is the number of imputations, generally speaking, the more the better. Originally (following Rubin, 1987) 5 was considered to be enough (hence the default). So from an accuracy point of view, 5 may be sufficient. However, this was based on an efficiency argument only. In order to achieve better estimates of standard errors, more imputations are needed. These days there is a rule of thumb to use whatever the average percentage rate of missingness is - so if there is 30% missing data on average in a dataset, use 30 imputations - see Bodner (2008) and White et al (2011) for further details.
# maxit is the number of iterations for each imputation. mice uses an iterative algorithm. It is important that the imputations for all variables reach convergence, otherwise they will be inaccurate. By inspecting the trace plots generated by plot() this can be visually determined. Unlike other Gibbs sampling methods, far fewer iterations are needed - generally in the region of 20-30 or less as a rule of thumb. When the trace lines reach a value and fluctuate slightly around it, convergence has been achieved.

m <- 30
maxit <- 40

# Impute + Diagnostics
# https://stefvanbuuren.name/fimd/sec-algoptions.html#sec:convergence
# https://stefvanbuuren.name/fimd/sec-diagnostics.html

## with specified predictors
country_mice <- mice(country_raw,
                     m=m, maxit=maxit, method='cart', seed=500, blocks = c("health_expend_perc", "human_consumption_ddd", "ln_livestock_consumption_kg_per_pcu", "ln_livestock_pcu"), predictorMatrix = pred_matrix) 

write_rds(country_mice, h("model/mice-imputation.rds"))
# plot(country_mice) # On convergence, the different streams should be freely intermingled with one another, without showing any definite trends. Convergence is diagnosed when the variance between different sequences is no larger than the variance within each individual sequence.
# densityplot(country_mice)
# stripplot(country_mice) # not working?
# show_imputes(country_mice, m = m, raw = country_raw)

## using full predictors
#country_mice_full <- mice(country_raw, m=m, maxit=maxit, method='cart', seed=500)
# plot(country_mice_full) # On convergence, the different streams should be freely intermingled with one another, without showing any definite trends. Convergence is diagnosed when the variance between different sequences is no larger than the variance within each individual sequence.
# densityplot(country_mice_full)
# stripplot(country_mice_full) # not working?
# show_imputes(country_mice_full, m = m, raw = country_raw)


# Model Runs
# Useful checks: https://cran.r-project.org/web/packages/bayesplot/vignettes/graphical-ppcs.html

## Full model, combine = TRUE
plan(multiprocess)
fit_combined <- brm_multiple(bf(n_amr_events ~  ln_livestock_consumption_kg_per_pcu + ln_livestock_pcu + 
                                 ln_migrant_pop_perc + ab_export_perc + health_expend_perc + 
                                  human_consumption_ddd + 
                                  ln_gdp_dollars + offset(ln_population),
                                zi ~ ln_pubs_sum + ln_gdp_dollars + ln_population),
                             data = country_mice,
                             inits = "0", 
                             iter = 4000,
                             control = list(adapt_delta = 0.9),
                             family = zero_inflated_poisson(),
                             cores = getOption("mc.cores", 4L),
                             combine = TRUE)
write_rds(fit_combined, h("model/fit_combined.rds"))
fit_combined_me <- marginal_effects(fit_combined)
write_rds(fit_combined_me, h("model/fit_combined_marginal_effects.rds"))


# Note about warning message

# Warning message:
#   Using only the first imputed data set. Please interpret the results with caution until a more principled approach has been implemented. 
# Note:
# brm_multiple combines the models into a single fitted model (see combine argument) 
# so it's okay to make predictions from the model object, and I think specifying newdata would mean the warning does not apply

## Full model, combine = FALSE
plan(multiprocess)
fit_all <- brm_multiple(bf(n_amr_events ~  ln_livestock_consumption_kg_per_pcu + ln_livestock_pcu + 
                                  ln_migrant_pop_perc + ab_export_perc + health_expend_perc + 
                                  human_consumption_ddd + 
                                  ln_gdp_dollars + offset(ln_population),
                                zi ~ ln_pubs_sum + ln_gdp_dollars + ln_population),
                             data = country_mice,
                        inits = "0", 
                        iter = 4000,
                        control = list(adapt_delta = 0.9),
                        family = zero_inflated_poisson(),
                        cores = getOption("mc.cores", 4L), 
                        combine = FALSE)
write_rds(fit_all, h("model/fit_all.rds"))
fit_all_me <- map(fit_all, ~marginal_effects(.))
write_rds(fit_all_me, h("model/fit_all_marginal_effects.rds"))

